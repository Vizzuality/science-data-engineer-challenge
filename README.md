# Data Engineer Challenge

## What is the purpose of this challenge?
With this challenge we would like to see a little bit more how you work and the way you make decisions, specifically, the challenge will help us see:

* your current technical abilities
* your thought process
* your ability to use data to support an argument or tell a story

The challenge will also help you get a glimpse of the real type of technical work we develop on our daily basis and the type of datasets we work with.

Please feel-free to surprise us, and showcase any skills that you think are important!.

Keep in mind that there is no right or wrong answer. If you feel like your analysis isn't perfect, don't worry. This is just
meant to be an exercise to help us gauge where you are in terms of your current capacity
and be a talking-point during the interview. A poor analysis will not necessarily
disqualify you from the job.

## The challenge:

One of our main focus right now are supply chains and how they affect the big challenges our world is facing today: climate change, water&food security and biodiversity loss.

* ### The data:
We would like you to use one of the datasets generated by the Spatial Production Allocation Model (SPAM). In particular we would like you to use the **2010** version of SPAM and we would like you to focus on the crop **soy bean**.

You can find all the information to retrieve the files in the [Mapspam site](https://www.mapspam.info/data/)

* ### The challenge question
We would like you to analyse the data related to the areas of interest in the [areas.geojson](./areas.geojson) file and **contextualize** it with at least one aditional dataset of your election (eg. [global forest change](https://glad.earthengine.app/view/global-forest-change#dl=1;old=off;bl=off;lon=20;lat=10;zoom=3) ) in the current world situation.

As a minimum we would like to see one map and a statistical chart.

* ### The tools
Use whatever tools you are comfortable with or you think are the best for the job, but keep in mind that the analysis should be reproducible and we will expect to see a script that describes a full pipe with the steps that you have followed in your analysis.

## How should I deliver the results?
Add your results to your Github profile in a Jupyter notebook that we could reproduce. Please submit your ideas within one week (max). This will give us enough time to review your challenge with the rest of the team before the next interview.

## How much time should I spend?
There is no time limit but we wouldn't want you to spend too much time working on this challenge, we understand you will probably have other things to do. We think that 4-8 hours should allow you to explore the dataset and create the minimum visualizations (chart + map).
## What if I have questions?
Email us any questions and we will answer as soon as possible

## What will happen in the interview?
* In the upcoming interview weâ€™ll focus on your coding challenge submission. We will **expect you to explain your analysis** to an audience that will include members of the Science team but also one or two people from other functional areas (Design, Front-End, Back-End, Project Manager,..). We will ask you any clarifying questions we might have.
* This will be an opportunity for you to provide some more context about the challenge, the assumptions you made, and add anything that you might want. The technical solution is not the only thing that we value, also your approach and explanations.
* Finally, we will also allocate some time for you to ask any questions about anything and everything you would like to know more about (ie. role, how we work at Vizzuality, our culture, benefits, etc.)
* The interview will last 120 minutes (max)
